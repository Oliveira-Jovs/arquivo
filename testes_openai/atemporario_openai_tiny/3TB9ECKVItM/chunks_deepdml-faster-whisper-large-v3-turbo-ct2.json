{
    "chunks": [
        "Olá, sejam muito bem-vindos a mais uma aula do curso de Linguagem de Programação Específica para IA. Hoje iremos explorar mais alguns conceitos de scheduling. O caso do conceito de hoje será o unroll. Ele, como a gente viu naquele exemplo didático com a geração de números de Fibonacci, pode ser utilizado para diminuir o número de iterações a custo do tamanho do corpo do loop. Então nós vamos aumentar o corpo do loop a fim de diminuir o número de iterações. A gente viu que ele tem um efeito de como se executasse múltiplas iterações em o que seria uma só no loop transformado. Ele pode ser útil para quando a gente tem pixels que manipulam dados incomuns. E um padrão específico que a gente vai ver frequentemente, que às vezes é útil utilizar o unroll, é quando a gente tem mais de um canal e quer simplesmente executar o assign desses canais, certo? Em sequência, então um atrás do outro sem uma criação de um novo loop. Ele tem duas sintaxes, a primeira delas é só passando uma var para dentro desse unroll e a outra var em um fator. Ele vai ser utilizado com bound ou com split. No caso aqui, quando a gente quer fazer um unroll, por exemplo, de uma var que não sejam esses canais, a gente normalmente precisa fazer um split dessa var, certo? E a gente faz o split com um fator e depois aplica um roll nessa var que vai estar ali bem interna no alinhamento do loop, certo? Uma outra opção é você simplesmente fazer essa sintaxe aqui, emroll, passando o var e depois o fator. A diferença é que você vai ficar escondido o split, certo? Ele vai esconder esse split. Para o exemplo dos canais, o que a gente vai estar utilizando é esse bound aqui. Então, nós vamos, na verdade, utilizar tanto o reorder como o bound para mover os canais para a parte mais interna do loop, certo? O bound, ele vai dizer para o relide que a minha variável do canal é limitada entre 0 a 3, certo? Então, ali, RGB, a gente sempre vai trabalhar em relide com o mínimo e o extent, né? Que é a extensão daquela dimensão. Então, a gente vai passar para o bound a variável, o mínimo, que vai ser 0, e o extent, que vai ser 3. E aqui são 3 canais. E a partir disso, né? Diferentemente da sintaxe aí com o split, a gente sabe os limites que esse loop vai percorrer. A gente sabe quais os limites da minha variável. Então, a gente utiliza o bound para passar essa informação para o onroll depois. No caso, onde a gente não sabe a dimensão do loop, que vai ser nos casos onde a gente tem uma variável que não seja aquela dos canais, por exemplo, a gente vai ter que estar utilizando essa sintaxe com o splitting. Iremos agora verificar na prática a utilização do onroll. Eu tenho aqui um exemplo onde eu estou aplicando um efeito sepia em uma imagem, certo? Então, nós temos um efeito de falta antiga sendo aplicado. Primeiramente, mostrando o protótipo de Python, para a gente ter um guia da temporização, certo? Do runtime dessa pipeline. Eu vou rodar o protótipo aqui. E nós temos, em Python, A velocidade de 20, no caso, ele está demorando 23 milissegundos, no caso, 24 milissegundos, para completar a execução da pipeline na média. No pior caso, está em 46 milissegundos, e no melhor caso, 20 milissegundos. A pipeline é simples, ela só envolve multiplicar os canais da imagem por diversos fatores, certo? Cada canal novo, ele vai ter um conjunto de três fatores associados a ele, certo? Então, cada novo canal da minha imagem, cada novo RGB, é uma ponderação dos RGB anteriores, iniciais. Após isso, eu faço o merging desses canais, converto para Uint8 a versão clipada dele, ou seja, mantida ali entre 0 e 35. Eu tenho aqui também um protótipo implementado em C++, com o OpenCV. Então, é a nossa segunda referência de tempo, e nós esperamos um tempo pouco menor de execução em relação ao Python. Já obtemos aqui, o resultado do OpenCV, está igualzinho ao do Python, e no caso, a gente tem aqui 0,3 milissegundos na média, certo? Em comparação ao Python, com os seus 23 milissegundos. No melhor caso, a gente tem 0,19 milissegundos, e no pior caso, 4 milissegundos, certo? Então, vai bem mais rápido que o Python. Vamos então ver se a gente consegue chegar mais rápido com o Raylide. Então, eu tenho aqui a pipeline implementada no Raylide, com o Generator, e com um parâmetro aqui para selecionar o Schedule customizado, certo? E aí, o que a gente tem aqui é esse Mux. E aí, no caso, a gente vai poder observar uma das maiores utilidades do Unroll, que é a eliminação do Select para fazer esse Assign dos canais, certo? Então, a gente tem um Mux aqui, e a gente consegue converter, ao invés de ter essa multiplexação, a gente vai converter isso daqui para executar o Assign um depois do outro ali, dentro do loop mais interno da minha pipeline. Então, eu tenho aqui primeiro a utilização com o paralelismo apenas sendo aplicado no Y, na história dessa imagem. Então, nós vamos verificar, ainda sem o Unroll, certo? Uma aplicação mais simples de Skyload. Ao executar isso aqui, a gente obtém um código também bem mais rápido que o Python, mas mais lento que o OPCV. Inclusive, o melhor tempo dessa execução em Haylite, é estar assinando a média em relação ao OpenCV, certo? Nós podemos, então, agora verificar o StateWinFile, que eu tenho já carregado aqui, eu só preciso recarregar essa página, vamos fechar o Assembly, e verificar aqui, né, que a gente tem esse Mox aqui dentro, internamente, no, a gente tem aqui o Y sendo executado em paralelo, e dentro do X, na parte mais interna, a gente tem esse Mox aqui, certo? Então, vamos remover esse Mox. Como a gente viu nos slides, a gente tem que utilizar algumas diretivas junto do meu Unroll, para poder ter o comportamento que nós esperamos. A primeira delas, como mencionado, é o Reorder. Nós precisamos mover os canais para a parte mais interna do Loop, certo? A gente tem que garantir que eles estejam na parte mais interna do alinhamento de Loop. Seguinte a isso, utilizamos o Bound para estabelecer os limites da minha var, né, que é os canais. E aí eu tenho o mínimo, que é 0, e a extensão dessa minha dimensão, que vai ser o 3. Então, a gente vai de 0 até 2, né, 0, 1 e 2. E, seguinte a isso, nós executamos o Unroll. Eu posso remover isso aqui, para que a gente veja um efeito que pode ser observado quando vocês estiverem utilizando essas diretivas, certo? Então, ao rodar o caso 1, a gente tem ainda uma pipeline um pouco mais lenta, inclusive. E, ao verificar a atualização aqui do Statement File, vou aumentar um pouco. Nós temos o seguinte, são três versões aqui da minha execução, certo? Uma para cada um daqueles canais.",
        "Então, é como se o relógio estivesse considerando o C, o canal, como o loop mais externo. Estamos reexecutando agora com o Compute Root. Para ver, né, o que o Nilay está fazendo por padrão com essa nossa pipeline. Eu vou recarregar o meu Statement File. E, como esperado, o C, né, o canal, ele está aqui, no loop mais externo. Então, ao fazer o Unroll, a gente estabelece vai ter esse Extent aqui com o Bound, certo? E, ao fazer o Unroll sem o Reorder, ele vai desenrolar essa computação em três loops diferentes, certo? Então, três loops por toda a imagem diferente. Vamos, então, remover e passar a fazer o Reorder junto com as duas outras diretivas. A gente tem um pouco mais rápido do que, né, o nosso teste lá, inicial, com aqueles três loops, certo? Mas ainda não tão rápido quanto o Paralelo e também não tão rápido quanto o OpenCV. Vamos, então, prosseguir com o Scheduling dessa Pipeline. Mas, antes, passando para verificar a nova estrutura obtida no Scheduling File. Então, nós temos aqui que temos o loop mais externo, o Image Output pelo Y, depois pelo X, e os três canais sendo feito o Assign em sequência, um após o outro. Iremos, então, passar para o Caso 2, que é a aplicação do Paralelismo após esse Unroll, certo? Dessa forma, com o Reorder e o Bounding. Achamos, agora, um aumento na velocidade em comparação, inclusive, ao Scheduling Zero, aqui. Onde a gente chegou a 0.29 milissegundos. Com o OpenCV aqui, já, na média, já atingindo um valor menor, certo? Inclusive, o pior caso, também. Já tem uma boa diferença. Nós podemos prosseguir com o nosso Scheduling, né? Fazendo, testando um Splitting e executando o Paralelismo a partir desse Splitting do Y, certo? Então, ao invés de paralelizar a var Y pura, a gente vai fazer um Splitting nela antes de aplicar o Paralelismo. E, novamente, como antes, eu estou utilizando o VectorSize obtido com a função NaturalVectorSize do Relied como uma guia para a minha experimentação. Ele é só um valor que eu posso rapidamente experimentar vários fatores dele como uma guia, certo? No caso aqui, eu estou multiplicando ele por 8. Então, nós vamos executar aqui o Caso 3. Ele é um pouco mais lento que a versão anterior. A gente pode experimentar, também, modificar esse VectorSize e ver se a gente obtém um tempo um pouco melhor. Ele está um pouco mais rápido, mas, ainda assim, não superou o nosso Scheduling 2. Nós iremos, então, observar o Scheduling 4, onde a gente encadeia o Splitting com a Vectorização, certo? O Paralelismo com a Vectorização. Nós executamos o nosso OneRow. Fazemos o Splitting do Y e aplicamos o Paralelismo na variável mais externa e fazemos o Splitting do X e aplicamos a Vectorização na variável mais interna, certo? Normalmente, a gente pode experimentar com diversos fatores desse número ou simplesmente ir variando manualmente os números, certo? Com isso, nós obtemos 0,1 milissegundos. Nós podemos, então, rodar novamente o Protosspint C++ como vou perceber. E, em comparação, nós temos aí metade do tempo na média com o Raylight. E aí, para observar o que acontece se você tenta executar essa mesma operação sem o OneRow, certo? Eu tenho o caso 5 aqui. Então, sem o OneRow, a gente consegue chegar abaixo do OpenCV na média, certo? Mas, não tão rápido quanto fazendo o OneRow. Inclusive, é também ali no range de metade do tempo em relação a esse Schedule 100 em OneRow. A gente pode testar também a reordenação. Nesse caso, sim. E aí, também é um pouco mais rápida, mas o melhor tempo está na mesma ordem ali do nosso Schedule 4. Aqui na média, no caso. Então, nós aplicamos o OneRow para tanto possibilitar algumas otimizações do nosso código como também eliminar o Mux dentro do loop mais interno para o nosso pipeline. Como leitura recomendada, eu deixo para vocês tanto a lição de Scheduleing do Raylight como também novamente o ponto em que o Raylight define ali definições relacionadas às funks, certo? Que vai conter as definições do Raylight, as duas definições do Raylight para o OneRow. Muito obrigado pela atenção de vocês e até a próxima. do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight do Raylight"
    ]
}