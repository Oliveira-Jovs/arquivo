{
    "chunks": [
        "Olá, seja muito bem-vindos a mais uma aula no curso de linguagem de programação específica para IA. Hoje iremos explorar mais alguns conceitos de Skyrim. O caso do conceito de hoje será o Unroll. Como vimos naquele exemplo didático com a geração de números de fibonate, pode ser utilizado para diminuir o número de interações a custo do tamanho do corpo do loop. Então, vamos aumentar o corpo do loop para diminuir o número de interações. A gente viu que ele tem um efeito de como se executassem múltiplas interações em o que seria um a só no loop transformado. Ele pode ser útil para quando a gente tem pixels que manipulam dados em comunes e um padrão específico que a gente vai ver frequentemente, e às vezes é útil utilizar o Unroll quando a gente tem mais de um canal e quer se perte executar o Assign desses canais, em sequência, um atrás do outro sem uma criação de um novo loop. Ele tem duas sintaxes, a primeira delas é só passando um Avar para dentro desse Unroll e a outra Avar em um fator. Ele vai ser utilizado com Bound ou com Split. No caso aqui, quando a gente quer fazer um Unroll por exemplo, de um Avar que não sejam os canais, a história normalmente precisa fazer um Split dessa Avar, certo? E a gente faz o Split com um fator e depois aplica um Unroll nessa Avar que vai estar ali bem interna no alinhamento do loop, certo? Uma outra opção é você se pente fazer essa sintax aqui, um Unroll passando o Avar e depois o fator. A diferença é que você vai ficar escondido o Split, certo? Ele vai esconder esse Split. Para o exemplo dos canais, a gente vai estar utilizando esse Bound aqui. Então, nós vamos, na verdade, utilizar tanto o Reorder como o Bound para mover os canais para a parte mais interna do loop, certo? O Bound, ele vai dizer para o Relide que a minha variável do canal é limitada entre 0 a 3, certo? Então ali, RGB, sempre que vai trabalhar em Relide com o mínimo e o Extend, que é a extensão daquela dimensão. Então, a gente vai passar para o Bound a variável, o mínimo que vai ser 0 e o Extend que vai ser 3, aqui são 3 canais. E a partir disso, diferentemente da sintax com o Split, a gente sabe os limites que esse loop vai percorrer, a gente sabe qual é o limite da minha variável. Então, a gente utiliza o Bound para passar essa informação para o Unroll depois. No caso, onde a gente não sabe a dimensão do looping, que vai ser, nos casos onde a gente tem uma variável que não seja aquela dos canais, por exemplo, a gente vai ter que estar utilizando essa sintax com o Split. Iremos agora verificar na prática a utilização do Unroll. Eu tenho aqui um exemplo, onde eu estou aplicando um efeito 7nm, certo? Então, nós temos um efeito de falta antiga sendo aplicado. Primeiramente, mostrando o Protótipo de Python para a gente ter um guia da temporização, certo, do runtime da pipeline. Eu vou rodar o Protótipo aqui. E nós temos, em Python, a velocidade de 20, no caso ele está demorando 23 ms, no caso 24 ms, para completar a execução da pipeline na média. No pior caso, está em 46 ms e, no melhor caso, 20 ms. A pipeline é simples, ela só envolve, multiplicar os canais da imagem por diversos fatores, certo? Cada canal novo, ele vai ter 3 fatores associados a ele, certo? Então, cada novo canal da imagem, cada novo RGIB, é uma ponderação dos RGIB anteriores, iniciais. Após isso, eu faço a merging desses canais, converto para a versão clipada dele, ou seja, mantida ali entre 0 e 35. Eu tenho aqui também um Protótipo implementado em C++, com OpenCV. Então, é a nossa segunda referência de tempo, e nós esperamos um tempo pouco menor de execução em relação ao Python. Já o termos aqui, o resultado do OpenCV, está igualzinho ao do Python. E, no caso, a gente tem aqui 0,3 ms na média, certo? Em comparação ao Python, com os seus 23 ms. No melhor caso, a gente tem 0,19 ms, e no pior caso, 4 ms. Então, está bem mais rápido que o Python. Vamos, então, ver se a gente consegue chegar mais rápido com o Relide. Então, eu tenho aqui a plana implementada no Relide com Generator, e com um parâmetro aqui para selecionar os carros que estão amizados, certo? E aí, o que a gente tem aqui é esse Mox. E aí, no caso, a gente vai poder observar uma das maiores utilidades do Unroll, que é a eliminação do Select para fazer esse Assign dos canais, certo? Então, a gente tem um Mox aqui e a gente consegue converter, ao invés de ter essa multiplexação, a gente vai converter isso aqui para executar o Assign um depois do outro ali, dentro do loop mais interno da minha pipeline. Então, eu tenho aqui primeiro a utilização, com o paralelismo apenas sendo aplicado no Y, no site da sem-mai. Então, nós vamos verificar, ainda sem o Unroll, certo? Uma aplicação mais simples de carros. Ao executar isso aqui, a gente obtém um código bem mais rápido que o Python, mais lento que o OPCV. Inclusive, o melhor tempo dessa execução em real-ight é assinando a média em relação ao OPCV, certo? Nós podemos, então, agora verificar o Satan File, que eu tenho já carregado aqui, eu só preciso recarregar essa página, vamos fechar o Assembly, e verificar aqui que a gente tem esse Mox aqui dentro internamente no... A gente tem aqui o Y sendo executado em paralelo, e dentro do Mox, na parte mais interna, tem esse Mox aqui, certo? Então, vamos remover esses Mox. Como a gente viu nos islades, a gente tem que utilizar algumas diretivas junto do meu Unroll, para poder ter o comportamento que nós esperamos. A primeira delas, como mencionado, é o ReOrder. Nós precisamos mover os canais para a parte mais interna do loop, certo? A gente tem que garantir que eles estejam na parte mais interna do alinhamento de loop. Seguinte a isso, utilizamos um Bound para estabelecer os limites da minha VAR, que são os canais. E aí, eu tenho o mínimo, que é 0, e a extensão dessa minha dimensão, que vai ser 3. Então, a gente vai de 0 até 2, 0, 1 e 2. E, seguinte a isso, nós executamos o Unroll. Eu posso remover isso aqui para que a gente veja um efeito que pode ser observado quando vocês estiverem utilizando essas diretivas, certo? Então, ao rodar o caso 1, a gente tem ainda uma papelária um pouco mais lente, inclusive, e ao verificar a atualização aqui do statement file, vou aumentar um pouco. Nós temos o seguinte, são três versões aqui da minha execução, certo? É só para cada um daqueles canais. Então, é como se ele estivesse considerando o C, o canal, como o loop mais externo. Vamos executando agora com o compute root,",
        "para ver o que ele está fazendo por padrão com essa nossa pipeline. Eu vou recarregar o meu statement file. E, como esperado, o C, o canal, ele está aqui no loop mais externo. Então, ao fazer o Unroll, a gente estabelece esse extent aqui com o bound, certo? E, ao fazer o Unroll sem o Reorder, ele vai desenrolar essa computação em três loops diferentes, certo? Então, três loops por toda imagem diferente. Vamos, então, remover e passar a fazer o order junto com as duas outras diretivas. A gente tem um pouco mais rápido do que o nosso teste inicial com aqueles três loops, certo? Mas ainda não tão rápido quanto o paralelo e também não quanto o OpenCV. Vamos, então, prosseguir com o scheduling dessa pipeline, mas antes, passando para verificar a nova estrutura obtida no statement file. Então, nós temos aqui que temos o loop mais externo em meio de output pelo Y, depois pelo X, e os três canais sendo feito o Assign em sequência, um após o outro. Iremos, então, passar para o caso 2, que é a aplicação do paralelismo após esse Unroll, certo? Então, vamos ver com o Reorder e o bounding. Achemos agora um aumento na velocidade, em comparação, inclusive, a o schedule 0 aqui. Quando a gente chegou a 0.29 milissegundos, com o OpenCV aqui, na média, já atingindo um valor menor, certo? Inclusive, o pior caso também. Tem uma boa diferença. Nós podemos prosseguir com o nosso scheduling, testando um splitting e executando o paralelismo a partir desse splitting do Y, certo? Então, em vez de paralelizar a var Y pura, a gente vai fazer um splitting nela antes de aplicar o paralelismo. E, novamente, como antes, eu estou utilizando vector size, obtido com a função natural vector size do realize, como uma guia para minha experimentação. É só um valor que eu posso, rapidamente, experimentar vários fatores dele, como uma guia, certo? No caso aqui, eu estou multiplicando ele por 8. Então, nós vamos executar aqui o caso 3. Era um pouco mais lento que a versão dele ovo. A gente pode experimentar também modificar esse vector size. Vê se a gente obtém um tempo um pouco melhor. Ele está um pouco mais rápido, mas ainda assim não superou o nosso schedule 2. Nós iremos então observar o schedule 4, onde a gente tem cadeia o splitting com a vectorização, certo? O paralelismo com a vectorização. Nós executamos o nosso unroll. Fazemos o splitting do y e aplicamos o paralelismo na variável mais externa. E fazemos o splitting do x e aplicamos a vectorização na variável mais interna, certo? Obviamente, a gente pode experimentar com diversos fatores desse número, ou simplesmente variando manualmente os números, certo? Com isso, nós obtemos 0,1 milissegundos. Nós podemos então rodar novamente o prototipin, de C++, com o opcv. E em comparação, nós temos a metade do tempo na média com o highlight. E aí, para observar o que acontece, você tenta executar essa mesma operação sem o unroll, certo? Eu tenho um caso 5 aqui. Então, sem o unroll, a gente consegue chegar abaixo do opcv na média, certo? Mas não tão rápido quanto fazendo o unroll. Inclusive, é também no range de metade do tempo em relação a esse schedule sem o unroll. A gente pode testar também a reordenação, esse caso 5. E aí, também, um pouco mais rápido, mas o melhor tempo está na mesma ordem do nosso schedule 4. Aqui na média, no caso. Então, nós aplicamos o unroll para, tanto, possibilitar algumas otimizações do nosso código, como também eliminar o moose dentro do loop mais interno para o nosso pipeline. Como a gente vai recomendada, eu deixo para vocês tanto a lição de scheduling do highlight, como também novamente o ponto entre highlight definições relacionadas às funks, que vai conter as definições do highlight, as duas definições do highlight, para o unroll. Muito obrigado pela atenção de vocês e até a próxima."
    ]
}